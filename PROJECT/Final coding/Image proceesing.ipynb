{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUDggQtzMGmn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Zfh7b8CaMujH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255, zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
      ],
      "metadata": {
        "id": "_KLU5c6VeJeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "jASfMOJmeOs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train_datagen.flow_from_directory(r\"/content/drive/MyDrive/Dataset/TEST_SET\",target_size=(64,64),class_mode='categorical',batch_size=24)\n",
        "x_test=test_datagen.flow_from_directory(r\"/content/drive/MyDrive/Dataset/TRAIN_SET\",target_size=(64,64),class_mode='categorical',batch_size=24)\n"
      ],
      "metadata": {
        "id": "2uLsovHQeUOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.class_indices)"
      ],
      "metadata": {
        "id": "_xpiydPKgHBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.class_indices)"
      ],
      "metadata": {
        "id": "VqnT_zlXgKTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np#used for numerical analysis\n",
        "import tensorflow #open source used for both ML and DL for computation\n",
        "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
        "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
        "#Dense layer is the regular deeply connected neural network layer\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "#Faltten-used fot flattening the input or change the dimension\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
        "#MaxPooling2D-for downsampling the image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "xy2vRvN3sTeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# First convolution layer and pooling\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second convolution layer and pooling\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flattening the layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2"
      ],
      "metadata": {
        "id": "Fxy07_pAsapW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()#summary of our model"
      ],
      "metadata": {
        "id": "wEU94FnosfSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the CNN\n",
        "#categorical_crossentropy for more than 2\n",
        "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IOEokJKzsjwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit_generator(\n",
        "         generator=x_train,steps_per_epoch = len(x_train),\n",
        "         epochs=10, validation_data=x_test,validation_steps = len(x_test))"
      ],
      "metadata": {
        "id": "_iIklm8mvaqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('nutrition.h5')"
      ],
      "metadata": {
        "id": "BKF2hgoVsyGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "jiCaWC_wszja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image \n",
        "model = load_model(\"nutrition.h5\")"
      ],
      "metadata": {
        "id": "ee-L99kKs3f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(r\"/content/n07740461_91.jpg\", grayscale=False,target_size= (64,64))\n",
        "img"
      ],
      "metadata": {
        "id": "DGCHLwBds6nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis = 0)\n",
        "pred = np.argmax(model.predict(x)) \n",
        "pred"
      ],
      "metadata": {
        "id": "qQBmOWoFs-03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
        "labels[np.argmax(pred)]\n"
      ],
      "metadata": {
        "id": "72cToY44tB3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}